{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow these: \n",
    "https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_rag_agent_llama3_local.ipynb\n",
    "https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_self_rag_local.ipynb\n",
    "\n",
    "TODO: change embeddings; adapt json output for groq -> json_mode: https://api.python.langchain.com/en/latest/chat_models/langchain_groq.chat_models.ChatGroq.html#langchain_groq.chat_models.ChatGroq.with_structured_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source ~/.zshrc\n",
    "# specify your working directory\n",
    "working_dir = \"/Users/pietro/open-modular-rag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from torch import cuda\n",
    "from typing import Callable\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "import chromadb\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metadata(metadata_str: str):\n",
    "    \"\"\" transforms relevant data from a data frame column into a dict format\n",
    "    Args:\n",
    "        metadata_str (_type_): column of a dataframe\n",
    "\n",
    "    Returns:\n",
    "        _type_: column in a dict format needed for the metadata chroma function\n",
    "    \"\"\"\n",
    "    metadata_dict = {}\n",
    "    if pd.notna(metadata_str):\n",
    "        # Assuming metadata is a string formatted as \"key: value, key: value\"\n",
    "        for part in metadata_str.split(\", \"):\n",
    "            if \": \" in part:\n",
    "                key, value = part.split(\": \", 1)\n",
    "                metadata_dict[key.strip()] = value.strip()\n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store preprocessed and chunked data to a defined directory\n",
    "combined_df = pd.read_parquet(working_dir + '/moreAgentsPaper.parquet', engine='fastparquet')\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"Metadata\"] = combined_df[\"Metadata\"].apply(parse_metadata)\n",
    "combined_df.Metadata.to_list()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract elements from dataframe and put them in a format suitable for chromadb\n",
    "metadatas = combined_df['Metadata'].tolist()\n",
    "ids = combined_df[['Chunk_ID']].apply(lambda x: ' '.join(x.dropna().values.tolist()), axis=1).tolist()\n",
    "documents_all = combined_df[['Content']].apply(lambda x: ' '.join(x.dropna().values.tolist()), axis=1).tolist() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize embedding model and embed chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_id = 'sentence-transformers/all-mpnet-base-v2'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=embed_model_id,\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'device': device, 'batch_size': 32},\n",
    "    cache_folder=working_dir + '/emb_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Embedding\n",
    "embeddings = embedding_model.embed_documents(documents_all)\n",
    "\n",
    "print(f\"We have {len(embeddings)} doc embeddings, each with \"\n",
    "      f\"a dimensionality of {len(embeddings[0])}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChromaDB setup to initilize collection including indeces of all documents\n",
    "# (in case of errors, perform pip uninstall chromadb and pip install chromadb)\n",
    "chroma_client = chromadb.PersistentClient(path=working_dir + \"/vectordb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide a name to setup and reference the vector index\n",
    "collection_name = \"more_agents_paper_self_rag\"\n",
    "# initialize the vector index with the respective similarity search metric\n",
    "vectorstore = chroma_client.get_or_create_collection(collection_name, metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the vector index with the preparred data\n",
    "vectorstore.upsert(\n",
    "    embeddings=embeddings,\n",
    "    documents=documents_all,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vectordb as a langchain object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I need to initialize a persistent chromadb client.\n",
    "- Then, I need to do `get_or_create_collection` to initialize a new collection\n",
    "- Then, I need to update the vector store.\n",
    "\n",
    "In a new notebook then I call again `get_or_create_collection` and initialize the langchain retriever from the chromadb collection as done in [here](https://python.langchain.com/docs/integrations/vectorstores/chroma/#passing-a-chroma-client-into-langchain)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
